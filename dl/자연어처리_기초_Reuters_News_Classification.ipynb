{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리 기초 Reuters News Classification.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "  # !sudo apt-get install -y fonts-nanum\n",
        "  # !sudo fc-cache -fv\n",
        "  # !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "  # 이 셀 실행후, 런타임 다시시작\n",
        "  "
      ],
      "metadata": {
        "id": "sfYcefdBp5Om"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ou9Oma8wK93q"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.rc('font', family='NanumBarunGothic')     # 한글 폰트\n",
        "# import matplotlib as mpl\n",
        "# mpl.rc('axes', unicode_minus=False)           # 유니코드 \"-\" sign\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.datasets import reuters\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global constants and hyper-parameters\n",
        "MY_SAMPLE = 2947\n",
        "NUM_CLASS = 46          # Classification class\n",
        "MY_NUM_WORDS = 2000     # number of words in dictionary\n",
        "\n",
        "\n",
        "MY_HIDDEN = 512         # \n",
        "MY_DROPOUT = 0.5        # Dropout rate : temporarily dropout given rate of cell's outputs to \"0\" : like Regularization\n",
        "\n",
        "MY_EPOCH = 10\n",
        "MY_BATCH = 64"
      ],
      "metadata": {
        "id": "OKkyP9HFLXzU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# DATABASE SETTING #\n",
        "####################\n",
        "# there are 46 news categories in reuters DB\n",
        "labels = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "          'housing','money-supply','coffee','sugar','trade','reserves', \n",
        "          'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
        "          'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "          'strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "          'rubber','heat','jobs','lei','bop','zinc','orange',\n",
        "          'pet- chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "metadata": {
        "id": "yMUJFzAsMF4A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape information\n",
        "def show_shape():\n",
        "  print('\\n== DB SHAPE INFO ==')\n",
        "  print('X_train shape = ', X_train.shape)\n",
        "  print('X_test shape = ', X_test.shape)\n",
        "  print('Y_train shape = ', Y_train.shape)\n",
        "  print('Y_test shape = ', Y_test.shape) \n",
        "  print()"
      ],
      "metadata": {
        "id": "CQ88jndsMktS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the DB and print shape info\n",
        "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = MY_NUM_WORDS, test_split = 0.3)\n",
        "\n",
        "show_shape()"
      ],
      "metadata": {
        "id": "S37tReOSMq80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ca1604-2965-4cf2-8bbe-02cd09e6d019"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859,)\n",
            "X_test shape =  (3369,)\n",
            "Y_train shape =  (7859,)\n",
            "Y_test shape =  (3369,)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pWrke2Bm3f6",
        "outputId": "2fc7e54e-df75-4d55-e862-ff16e0319957"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistics on how many articles per category in the train DB\n",
        "# numpy unique is useful in this case\n",
        "print('\\n== TRAIN DATA CONTENT INFO ==')\n",
        "unique, counts = np.unique(Y_train, return_counts = True)\n",
        "for i in range(len(unique)):\n",
        "  print(unique[i], labels[i], \"=\", counts[i])"
      ],
      "metadata": {
        "id": "kwKoV3cdMyhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523bed3c-c1c5-41a4-f00b-33350bd457dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== TRAIN DATA CONTENT INFO ==\n",
            "0 cocoa = 50\n",
            "1 grain = 378\n",
            "2 veg-oil = 66\n",
            "3 earn = 2769\n",
            "4 acq = 1701\n",
            "5 wheat = 14\n",
            "6 copper = 39\n",
            "7 housing = 15\n",
            "8 money-supply = 126\n",
            "9 coffee = 93\n",
            "10 sugar = 114\n",
            "11 trade = 337\n",
            "12 reserves = 40\n",
            "13 ship = 149\n",
            "14 cotton = 18\n",
            "15 carcass = 19\n",
            "16 crude = 387\n",
            "17 nat-gas = 33\n",
            "18 cpi = 59\n",
            "19 money-fx = 475\n",
            "20 interest = 238\n",
            "21 gnp = 91\n",
            "22 meal-feed = 10\n",
            "23 alum = 36\n",
            "24 oilseed = 56\n",
            "25 gold = 77\n",
            "26 tin = 18\n",
            "27 strategic-metal = 13\n",
            "28 livestock = 43\n",
            "29 retail = 19\n",
            "30 ipi = 38\n",
            "31 iron-steel = 34\n",
            "32 rubber = 30\n",
            "33 heat = 9\n",
            "34 jobs = 43\n",
            "35 lei = 10\n",
            "36 bop = 46\n",
            "37 zinc = 17\n",
            "38 orange = 16\n",
            "39 pet- chem = 20\n",
            "40 dlr = 32\n",
            "41 gas = 28\n",
            "42 silver = 10\n",
            "43 wpi = 19\n",
            "44 hog = 10\n",
            "45 lead = 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gaL6dV50M7J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# my_array = [1, 1, 2, 2, 2, 3]\n",
        "# unique, count = np.unique(my_array, return_counts = True)\n",
        "\n",
        "# # print the result\n",
        "# print(unique)\n",
        "# print(count)"
      ],
      "metadata": {
        "id": "dk48PHbRM4Ca"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, count = np.unique(Y_train, return_counts=True)\n",
        "print(Y_train)    # 7859\n",
        "print(unique)     # Category\n",
        "print(count)      # records per category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjtNNu1WnXfs",
        "outputId": "21aeeba6-476c-4eb7-d6e6-1f8d3f20a456"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  4  3 ...  4 16  3]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
            "[  50  378   66 2769 1701   14   39   15  126   93  114  337   40  149\n",
            "   18   19  387   33   59  475  238   91   10   36   56   77   18   13\n",
            "   43   19   38   34   30    9   43   10   46   17   16   20   32   28\n",
            "   10   19   10   14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the same statistics visually\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.figure(1)\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.hist(Y_train, bins='auto')\n",
        "plt.xlabel(\"카테고리\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Train data\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.hist(Y_test, bins='auto')\n",
        "plt.xlabel(\"카테고리\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Test data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-nV-bI_mNExt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "7e7e40d3-5003-4aeb-bf33-c3b5d81e116f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52852 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53580 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52852 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53580 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample data in its raw format\n",
        "print('\\n== SAMPLE ARTICLE (RAW) ==')\n",
        "print(\"article #\", MY_SAMPLE)\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])\n",
        "print(\"number of words\", len(X_train[MY_SAMPLE]))\n",
        "print(X_train[MY_SAMPLE])\n",
        "\n",
        "# python dictionary: word -> index\n",
        "# zero index is not used\n",
        "word_to_id = reuters.get_word_index()\n",
        "print('\\n== DICTIONARY INFO ==')\n",
        "print(\"There are\", len(word_to_id) + 1, \"words in the dictionary.\")\n",
        "print('The index of \"the\" is', word_to_id['the'])"
      ],
      "metadata": {
        "id": "NCct_CMPNIXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3b86e4-6ba1-4c49-cee2-1bfdc31cec13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (RAW) ==\n",
            "article # 2947\n",
            "category 4 acq\n",
            "number of words 61\n",
            "[1, 2, 1229, 81, 8, 16, 515, 25, 270, 5, 4, 2, 1229, 111, 267, 7, 73, 2, 2, 7, 108, 13, 80, 1448, 28, 365, 12, 11, 15, 1986, 2, 69, 158, 18, 1296, 1275, 7, 2, 1627, 2, 2, 4, 393, 374, 1229, 323, 5, 2, 1229, 7, 2, 9, 25, 2, 473, 936, 4, 49, 8, 17, 12]\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n",
            "\n",
            "== DICTIONARY INFO ==\n",
            "There are 30980 words in the dictionary.\n",
            "The index of \"the\" is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python dictionary: index -> word\n",
        "# this is the opposite to word_to_id dictionary\n",
        "id_to_word = {}\n",
        "for key, value in word_to_id.items():\n",
        "  id_to_word[value] = key"
      ],
      "metadata": {
        "id": "fwaJEa8GNT4R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to translate the sample review\n",
        "# we use python dictionary get() function\n",
        "# it returns \"???\" if the ID is not found\n",
        "# index is subtracted by 3 to handle first 3 special characters\n",
        "#   index 0 is for padding (= filling empty space)\n",
        "#   index 1 is for indicating the beginning of a review\n",
        "#   index 2 is for dropped word (= out of bound)\n",
        "# we use python list and join() function to concatenate the words"
      ],
      "metadata": {
        "id": "fH2_oAl6NXW0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoding():\n",
        "  decoded = []\n",
        "  for i in X_train[MY_SAMPLE]:\n",
        "    word = id_to_word.get(i - 3, \"???\")\n",
        "    decoded.append(word)\n",
        "\n",
        "  print('\\n== SAMPLE ARTICLE (DECODED) ==')\n",
        "  print(\" \".join(decoded))\n",
        "  \n",
        "decoding()\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])"
      ],
      "metadata": {
        "id": "meJ0vAPXNhAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b910f8-8e21-4097-9290-f28e2adeab5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (DECODED) ==\n",
            "??? ??? telephone corp said it completed its acquisition of the ??? telephone co based in new ??? ??? in exchange for stock valued at 26 3 mln dlrs enterprises ??? about 16 000 access lines in ??? county ??? ??? the third operating telephone subsidiary of ??? telephone in ??? and its ??? largest overall the company said reuter 3\n",
            "category 4 acq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will NOT do padding (as in movie review classification)\n",
        "# instead we will do tokenization for the inputs\n",
        "# we get a numpy array of size MY_NUM_WORDS for each input \n",
        "# the entries are integer counts \n",
        "# the resulting matrix is very big\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# for i in range(10):\n",
        "#   print(len(X_train[i]))\n",
        "\n",
        "Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "\n",
        "print('before:', X_train[0])\n",
        "print('number before:', len(X_train[0]))\n",
        "X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "print('after:', X_train[0])\n",
        "print('number after:', len(X_train[0]))\n",
        "\n",
        "X_test = Tok.sequences_to_matrix(X_test, mode = 'count')"
      ],
      "metadata": {
        "id": "21DXQk4-Nt0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72df1fd-397a-49f0-ec36-860973d4a31e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "number before: 87\n",
            "after: [0. 1. 4. ... 0. 0. 0.]\n",
            "number after: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "# X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "# X_test = Tok.sequences_to_matrix(X_test, mode = 'count’)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (TOKENIZED INPUT) ==')\n",
        "sample = X_train[MY_SAMPLE]\n",
        "print(*sample, sep = ' ')\n",
        "print(\"Array size:\", len(sample))\n",
        "print(\"Sum of entries:\", np.sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6IvUSlAuxkw",
        "outputId": "be84c1f7-ba37-4eef-d093-e107772deac2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (TOKENIZED INPUT) ==\n",
            "0.0 1.0 11.0 0.0 3.0 2.0 0.0 4.0 2.0 1.0 0.0 1.0 2.0 1.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "Array size: 2000\n",
            "Sum of entries: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output reshaping using one-hot encoding\n",
        "# from keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train, NUM_CLASS)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASS)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==')\n",
        "sample = Y_train[MY_SAMPLE]\n",
        "print(sample)\n",
        "print(\"Array size:\", len(sample))\n",
        "\n",
        "show_shape()\n"
      ],
      "metadata": {
        "id": "sOnatkWcN8Z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847cfc7c-ce03-4983-f027-a7f28588dea9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Array size: 46\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859, 2000)\n",
            "X_test shape =  (3369, 2000)\n",
            "Y_train shape =  (7859, 46)\n",
            "Y_test shape =  (3369, 46)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "# MODEL BUILDING AND TRAINING #\n",
        "###############################\n",
        "# build a keras sequential model of our DNN\n",
        "# softmax is needed for multi-class classification\n",
        "model = Sequential()\n",
        "model.add(Dense(units=MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))\n",
        "# model.add(Dense(MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))  => have to give Tuple, eg (MY_NUM_WORDS,)\n",
        "model.add(Activation('relu'))       # later comment this out or use others, \n",
        "model.add(Dropout(MY_DROPOUT))\n",
        "model.add(Dense(NUM_CLASS))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xapmZb7pN_ZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a07b40b-4baf-4203-cad5-85fbffab184c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1024512   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 46)                23598     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 46)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,048,110\n",
            "Trainable params: 1,048,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using the model\n",
        "# shape needs to change from (2000,) to (1, 2000)\n",
        "def ask_question():\n",
        "  sample = X_train[MY_SAMPLE]\n",
        "  sample = sample.reshape(1, sample.shape[0])\n",
        "  pred = model.predict(sample, verbose = 0)\n",
        "  guess = np.argmax(pred)\n",
        "  answer = np.argmax(Y_train[MY_SAMPLE])\n",
        "  \n",
        "  print('\\n== SAMPLE QUESTION ==')\n",
        "  print(\"My guess for sample article:\", guess, labels[guess])\n",
        "  print(\"The answer is:\", answer, labels[answer]) \n",
        "  print()\n",
        "\n",
        "ask_question()"
      ],
      "metadata": {
        "id": "_BtHybqwOJYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242e1680-2e18-44ba-c4db-2ebfc0055b37"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE QUESTION ==\n",
            "My guess for sample article: 12 reserves\n",
            "The answer is: 4 acq\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training and saving\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = MY_EPOCH, batch_size = MY_BATCH, verbose = 1)\n",
        "model.save('chap2.h5')"
      ],
      "metadata": {
        "id": "gXNO6YchOQpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6381f7-ee54-4a60-f6ac-960b11961205"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "123/123 [==============================] - 2s 6ms/step - loss: 1.6289 - accuracy: 0.6710 - val_loss: 1.0949 - val_accuracy: 0.7700\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.8433 - accuracy: 0.8173 - val_loss: 0.9468 - val_accuracy: 0.7955\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.8658 - val_loss: 0.8747 - val_accuracy: 0.8142\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.4297 - accuracy: 0.9002 - val_loss: 0.8881 - val_accuracy: 0.8094\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.9172 - val_loss: 0.9051 - val_accuracy: 0.8151\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.9291 - val_loss: 0.9349 - val_accuracy: 0.8157\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.9410 - val_loss: 0.9384 - val_accuracy: 0.8145\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.2244 - accuracy: 0.9449 - val_loss: 1.0025 - val_accuracy: 0.8074\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9515 - val_loss: 0.9810 - val_accuracy: 0.8112\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9500 - val_loss: 1.0373 - val_accuracy: 0.8097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# MODEL EVALUATION #\n",
        "####################\n",
        "# evaluate the model and calculate loss and accuracy\n",
        "score = model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "print('Prediction for the first news: ', pred[0])\n",
        "print(np.argmax(pred[0])) \n",
        "print('Answer: ', Y_test[0])\n",
        "print(labels[np.argmax(Y_test[0])]) \n",
        "\n",
        "\n",
        "# ask_question()"
      ],
      "metadata": {
        "id": "A6jJWOAwObWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31fb630-9c65-4d64-c238-2a76788425da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.8097\n",
            "Test loss: 1.0372653007507324\n",
            "Test accuracy: 0.8097358345985413\n",
            "Prediction for the first news:  [1.13399074e-06 2.01395073e-04 3.07033843e-05 9.96004879e-01\n",
            " 2.38439708e-04 3.62730725e-06 1.52149914e-06 1.48522277e-05\n",
            " 1.25390099e-04 2.84644757e-05 3.71258066e-05 2.50187673e-04\n",
            " 2.91554054e-04 6.44085376e-05 1.68157585e-05 2.47291746e-06\n",
            " 1.14519743e-03 3.28429178e-06 1.72884011e-05 5.71767392e-04\n",
            " 3.65449814e-04 1.29184380e-04 4.52979430e-06 1.48483673e-06\n",
            " 3.22295382e-05 5.41199051e-06 8.02841043e-07 4.23572914e-07\n",
            " 1.08387167e-05 2.01369903e-06 1.01939004e-04 4.34916683e-06\n",
            " 1.60391370e-04 1.89206673e-06 2.18350888e-05 1.81127939e-06\n",
            " 5.32317172e-05 7.32267426e-06 1.22579104e-05 5.21177299e-06\n",
            " 5.48038315e-06 2.52385416e-06 1.71270142e-06 5.13647501e-06\n",
            " 2.09377077e-07 1.18559292e-05]\n",
            "3\n",
            "Answer:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "earn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TCwcu5KBfP2D"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}